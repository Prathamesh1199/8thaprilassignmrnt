{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "1:\n In order to evaluate the performance of an SVM regression model for predicting house prices\nbased on several characteristics, the following regression metrics can be use   \n\n1.Mean Squared Error (MSE) \n2.Root Mean Squared Error (RMSE)    \n3.Mean Absolute Error (MAE)\n4.R-Squared (R2)                     \n                     \n        ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "2:\n If the goal is to predict the actual price of a house as accurately as possible using \nan SVM regression model, the Mean Squared Error (MSE) would be the more appropriate\nevaluation metric to use.\n\nMSE measures the average of the squared differences between the predicted and actual \nvalues, which means that it penalizes large errors more heavily than small errors. \nTherefore, if the goal is to minimize the overall prediction error and get as close\nas possible to the true house prices, then using MSE as an evaluation metric is ideal.\n\nOn the other hand, R-squared measures the proportion of variance in the dependent variable \nthat is explained by the independent variables. While R-squared can be a useful metric \nfor understanding the goodness of fit of a model, it does not directly measure the accuracy\nof individual predictions.\n\nTherefore, in this scenario, it would be more appropriate to use MSE as the evaluation\nmetric since the goal is to minimize prediction error and get as close as possible to \nthe true house prices.   ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "3:\n    \nWhen dealing with a dataset that has a significant number of outliers, it is best to use\nrobust regression metrics that are less sensitive to outliers. The two most common robust \nregression metrics are Mean Absolute Error (MAE) and Huber Loss.\n\nMAE measures the absolute differences between the predicted and actual values, and it is \nless sensitive to outliers than Mean Squared Error (MSE). This is because MAE does not \nsquare the residuals, and thus, the impact of large errors is reduced.\n\nHuber Loss is a hybrid between MAE and MSE and is designed to be less sensitive to outliers\nthan MSE. It uses a parameter delta to control the degree of resistance to outliers, with \nsmaller values of delta resulting in greater robustness to outliers.\n\nTherefore, in this scenario, either MAE or Huber Loss would be the most appropriate regression \nmetric to use with an SVM model. These robust regression metrics can handle outliers better \nthan MSE or R-squared and provide more accurate performance measures for the SVM model.    \n    \n    \n    \n    \n    \n    ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "4:\nIf both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) values are very close,\neither of these metrics can be used to evaluate the performance of an SVM regression model\nusing a polynomial kernel. However, RMSE may be a more appropriate metric since it is more \ninterpretable than MSE.\n\nRMSE is simply the square root of MSE and gives an idea of how far the predictions are from\nthe actual values on average. It has the same units as the dependent variable, which makes\nit more interpretable than MSE.\n\nFor example, if the target variable is the price of a house, RMSE would be in the same units \nas the price (e.g., dollars). This means that a value of RMSE = 10,000 would indicate that the\nmodel's predictions are off by $10,000 on average.\n\nIn contrast, MSE would be in squared units (e.g., dollars squared), which can be difficult to\ninterpret. For this reason, RMSE is often preferred over MSE when interpreting the results of\na regression model.\n\nTherefore, if both MSE and RMSE values are very close, using RMSE to evaluate the performance\nof an SVM regression model with a polynomial kernel is likely the best choice.    ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "5:\n If the goal is to measure how well an SVM regression model with different kernels explains \nthe variance in the target variable, then the most appropriate evaluation metric is the \ncoefficient of determination, or R-squared.\n\nR-squared measures the proportion of variance in the dependent variable (i.e., the target variable) \nthat is explained by the independent variables (i.e., the features used in the regression model). \nIt takes a value between 0 and 1, with higher values indicating that the model is better at explaining\nthe variance in the target variable.\n\nTherefore, when comparing the performance of different SVM regression models using different kernels,\nR-squared is the most appropriate evaluation metric if the goal is to measure how well the model explains\nthe variance in the target variable. This metric will help to determine which kernel provides the best fit\nto the data and the best explanation for the variance in the target variable.\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}